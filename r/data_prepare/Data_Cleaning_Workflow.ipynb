{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203e4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b1825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/mnt/ufs18/home-146/naultran/R/x86_64-conda-linux-gnu-library/4.3\"                                \n",
      "[2] \"/cvmfs/ubuntu_2204.icer.msu.edu/2023.06/x86_64/amd/zen3/software/R/4.3.2-gfbf-2023a/lib/R/library\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    ".libPaths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92287732",
   "metadata": {},
   "source": [
    "## Load python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4624ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d17f85",
   "metadata": {},
   "source": [
    "## Load R packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "187aa375",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    ".libPaths(\"/mnt/gs21/scratch/naultran/Rlocal4.3.2\")\n",
    "#install.packages(\"remotes\")\n",
    "#remotes::install_version(\"Matrix\", version = \"1.6-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7b6b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in library(recount3) : there is no package called ‘recount3’\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in library(recount3) : there is no package called ‘recount3’\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line '\\n#source(\"../renv/activate.R\")\\n#library(SummarizedExperiment)\\nlibrary(recount3)\\n'.\nR error message: 'Error in library(recount3) : there is no package called ‘recount3’'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in library(recount3) : there is no package called ‘recount3’\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#source(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../renv/activate.R\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m#library(SummarizedExperiment)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mlibrary(recount3)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2474\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m/mnt/ufs18/nodr/home/naultran/miniforge-envs/tox_reticula/lib/python3.9/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line '\\n#source(\"../renv/activate.R\")\\n#library(SummarizedExperiment)\\nlibrary(recount3)\\n'.\nR error message: 'Error in library(recount3) : there is no package called ‘recount3’'"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(SummarizedExperiment)\n",
    "library(recount3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6666d04",
   "metadata": {},
   "source": [
    "# Test API from Recount3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296a74aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:03.326727 downloading and reading the metadata.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ufs18/home-146/naultran/.cache/R/recount3\n",
      "  does not exist, create directory? (yes/no): yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:09.859211 caching file sra.sra.SRP104670.MD.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/data_sources/sra/metadata/70/SRP104670/sra.sra.SRP104670.MD.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 460 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 460 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 460 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:11.272542 caching file sra.recount_project.SRP104670.MD.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/data_sources/sra/metadata/70/SRP104670/sra.recount_project.SRP104670.MD.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:12.416201 caching file sra.recount_qc.SRP104670.MD.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/data_sources/sra/metadata/70/SRP104670/sra.recount_qc.SRP104670.MD.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:13.709852 caching file sra.recount_seq_qc.SRP104670.MD.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/data_sources/sra/metadata/70/SRP104670/sra.recount_seq_qc.SRP104670.MD.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:15.036897 caching file sra.recount_pred.SRP104670.MD.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/data_sources/sra/metadata/70/SRP104670/sra.recount_pred.SRP104670.MD.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:16.094178 downloading and reading the feature information.\n",
      "\n",
      "R[write to console]: 2025-03-21 21:39:16.429058 caching file mouse.gene_sums.M023.gtf.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/annotations/gene_sums/mouse.gene_sums.M023.gtf.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 440 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 440 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 440 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |=                                                                     |   1%\n",
      "  |                                                                            \n",
      "  |===                                                                   |   4%\n",
      "  |                                                                            \n",
      "  |=======                                                               |  10%\n",
      "  |                                                                            \n",
      "  |===========                                                           |  15%\n",
      "  |                                                                            \n",
      "  |==============                                                        |  20%\n",
      "  |                                                                            \n",
      "  |===============                                                       |  21%\n",
      "  |                                                                            \n",
      "  |===================                                                   |  27%\n",
      "  |                                                                            \n",
      "  |======================                                                |  32%\n",
      "  |                                                                            \n",
      "  |==========================                                            |  38%\n",
      "  |                                                                            \n",
      "  |==============================                                        |  42%\n",
      "  |                                                                            \n",
      "  |==============================                                        |  43%\n",
      "  |                                                                            \n",
      "  |==================================                                    |  49%\n",
      "  |                                                                            \n",
      "  |======================================                                |  54%\n",
      "  |                                                                            \n",
      "  |==========================================                            |  60%\n",
      "  |                                                                            \n",
      "  |=============================================                         |  64%\n",
      "  |                                                                            \n",
      "  |=================================================                     |  70%\n",
      "  |                                                                            \n",
      "  |=====================================================                 |  75%\n",
      "  |                                                                            \n",
      "  |=======================================================               |  78%\n",
      "  |                                                                            \n",
      "  |===========================================================           |  84%\n",
      "  |                                                                            \n",
      "  |=============================================================         |  87%\n",
      "  |                                                                            \n",
      "  |=================================================================     |  92%\n",
      "  |                                                                            \n",
      "  |====================================================================  |  97%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:18.514723 downloading and reading the counts: 48 samples across 55421 features.\n",
      "\n",
      "R[write to console]: 2025-03-21 21:39:18.878999 caching file sra.gene_sums.SRP104670.M023.gz.\n",
      "\n",
      "R[write to console]: adding rname 'http://duffel.rail.bio/recount3/mouse/data_sources/sra/gene_sums/70/SRP104670/sra.gene_sums.SRP104670.M023.gz'\n",
      "\n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "Downloading: nsole]: \n",
      "R[write to console]: \n",
      "R[write to console]: 480 B\n",
      "R[write to console]: \n",
      "R[write to console]:      \n",
      "  |                                                                            \n",
      "  |                                                                      |   0%\n",
      "  |                                                                            \n",
      "  |==                                                                    |   3%\n",
      "  |                                                                            \n",
      "  |===                                                                   |   5%\n",
      "  |                                                                            \n",
      "  |=====                                                                 |   8%\n",
      "  |                                                                            \n",
      "  |=======                                                               |  10%\n",
      "  |                                                                            \n",
      "  |=========                                                             |  13%\n",
      "  |                                                                            \n",
      "  |===========                                                           |  16%\n",
      "  |                                                                            \n",
      "  |============                                                          |  18%\n",
      "  |                                                                            \n",
      "  |==============                                                        |  20%\n",
      "  |                                                                            \n",
      "  |================                                                      |  23%\n",
      "  |                                                                            \n",
      "  |==================                                                    |  25%\n",
      "  |                                                                            \n",
      "  |====================                                                  |  28%\n",
      "  |                                                                            \n",
      "  |======================                                                |  31%\n",
      "  |                                                                            \n",
      "  |========================                                              |  34%\n",
      "  |                                                                            \n",
      "  |=========================                                             |  36%\n",
      "  |                                                                            \n",
      "  |===========================                                           |  39%\n",
      "  |                                                                            \n",
      "  |=============================                                         |  41%\n",
      "  |                                                                            \n",
      "  |===============================                                       |  44%\n",
      "  |                                                                            \n",
      "  |=================================                                     |  47%\n",
      "  |                                                                            \n",
      "  |===================================                                   |  50%\n",
      "  |                                                                            \n",
      "  |====================================                                  |  52%\n",
      "  |                                                                            \n",
      "  |========================================                              |  57%\n",
      "  |                                                                            \n",
      "  |===========================================                           |  61%\n",
      "  |                                                                            \n",
      "  |==============================================                        |  65%\n",
      "  |                                                                            \n",
      "  |=================================================                     |  69%\n",
      "  |                                                                            \n",
      "  |==================================================                    |  71%\n",
      "  |                                                                            \n",
      "  |====================================================                  |  75%\n",
      "  |                                                                            \n",
      "  |=======================================================               |  78%\n",
      "  |                                                                            \n",
      "  |=========================================================             |  81%\n",
      "  |                                                                            \n",
      "  |===========================================================           |  85%\n",
      "  |                                                                            \n",
      "  |==============================================================        |  88%\n",
      "  |                                                                            \n",
      "  |================================================================      |  92%\n",
      "  |                                                                            \n",
      "  |===================================================================   |  95%\n",
      "  |                                                                            \n",
      "  |===================================================================== |  98%\n",
      "  |                                                                            \n",
      "  |======================================================================| 100%\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2025-03-21 21:39:20.238648 constructing the RangedSummarizedExperiment (rse) object.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [2] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [3] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [4] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [5] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [6] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [7] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [8] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      " [9] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[10] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[11] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[12] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[13] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[14] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[15] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[16] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[17] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[18] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[19] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[20] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[21] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[22] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[23] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[24] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[25] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[26] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[27] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[28] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[29] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[30] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[31] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[32] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[33] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[34] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[35] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[36] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[37] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[38] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[39] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[40] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[41] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[42] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[43] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[44] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[45] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[46] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[47] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n",
      "[48] \"Diurnal liver transcriptome in wt and nono-/- mice\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "tryCatch({\n",
    "    rse_gene <- recount3::create_rse_manual(\n",
    "        project = \"SRP104670\",\n",
    "        project_home = \"data_sources/sra\",\n",
    "        organism = \"mouse\",\n",
    "        annotation = \"gencode_v23\",\n",
    "        type = \"gene\")\n",
    "    \n",
    "    colData(rse_gene)$sra.study_title\n",
    "    \n",
    "    },error=function(cond){\n",
    "        print(cond)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7a655",
   "metadata": {},
   "source": [
    "# Download Data From Recount3\n",
    "\n",
    "This R code processes a manually curated list of RNA-seq projects from recount3, specified in a CSV file. It iterates through each project, retrieving metadata for those with 600 or fewer samples using create_rse_manual(), and saves the extracted metadata as a text file. Errors are handled gracefully by printing the sample count of failed projects instead of interrupting execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2772ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "data <- read.csv(\"../inputs/recount3_selection_2024-04-12.csv\")\n",
    "\n",
    "for (i in 1:nrow(data)) {\n",
    "\n",
    "  if (data$n_samples[i] <= 600) {\n",
    "      tryCatch({\n",
    "        rse_gene <- recount3::create_rse_manual(\n",
    "          project = data$project[i],\n",
    "          project_home = data$project_home[i],\n",
    "          organism = data$organism[i],\n",
    "          annotation = \"gencode_v23\",\n",
    "          type = \"gene\"\n",
    "        )\n",
    "\n",
    "        output_path <- paste0(\"/mnt/home/yuankeji/RanceLab/reticula_new/downloadFromRecount3/rse_gene_\", data$project[i], \".txt\")\n",
    "        write.table(data.frame(colData(rse_gene)), file = output_path, sep = '\\t', quote = FALSE)\n",
    "      },\n",
    "      error = function(cond){\n",
    "          print(data$n_samples[i])\n",
    "      }\n",
    "    )\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75a7ea",
   "metadata": {},
   "source": [
    "# Export metadata (sra.experiment_attributes) into .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f63a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_attributes(attr_str):\n",
    "    \"\"\" Parse the attribute string into a dictionary \"\"\"\n",
    "    if pd.isna(attr_str):\n",
    "        return {}\n",
    "    attrs = attr_str.split('|')\n",
    "    attr_dict = {}\n",
    "    for attr in attrs:\n",
    "        if ';;' in attr:\n",
    "            key, value = attr.split(';;', 1)\n",
    "            attr_dict[key] = value\n",
    "    return attr_dict\n",
    "\n",
    "# Directory containing the files\n",
    "input_directory = '../inputs/downloadFromRecount3/'\n",
    "output_directory = '../outputs/reticula_new/'\n",
    "output_file = 'combined_data_all_duplicate.csv'\n",
    "\n",
    "# List all text files in the directory\n",
    "file_paths = glob.glob(os.path.join(input_directory, '*.txt'))\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "# Process each file\n",
    "for index, file_path in enumerate(file_paths):\n",
    "    try:\n",
    "        print(f\"Processing file {index}: {file_path}\")\n",
    "        # Read the file\n",
    "        data = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "        # Drop duplicate entries in 'sra.experiment_attributes' before parsing\n",
    "        # unique_attributes = data['sra.sample_attributes'].drop_duplicates()\n",
    "        unique_attributes = data['sra.sample_attributes']\n",
    "\n",
    "        # Apply the parsing function to the unique 'sra.experiment_attributes' column\n",
    "        unique_attributes = unique_attributes.apply(parse_attributes)\n",
    "\n",
    "        # Convert the dictionary column to separate columns\n",
    "        attributes_df = pd.DataFrame(unique_attributes.tolist(), index=unique_attributes.index)\n",
    "\n",
    "        # Set the index name to the file name for clarity\n",
    "        attributes_df.index.name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "        # Combine with the main DataFrame\n",
    "        combined_df = pd.concat([combined_df, attributes_df])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        break\n",
    "\n",
    "combined_df.to_csv(os.path.join(output_directory, output_file), sep='\\t')\n",
    "\n",
    "\n",
    "print(f\"Data combined and saved to {os.path.join(output_directory, output_file)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d441b3",
   "metadata": {},
   "source": [
    "If the combined_data_all_duplicate.csv file is too large, you can use following code to split it into several part so that can run the following code without interrupting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d87285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split file at the begining\n",
    "df = pd.read_csv(output_directory + 'combined_data_all_duplicate.csv', sep='\\t', dtype=str)\n",
    "\n",
    "part_size = len(df) // 3\n",
    "\n",
    "df.iloc[:part_size].to_csv(output_directory + 'part1.csv', sep='\\t', index=False)\n",
    "df.iloc[part_size:2*part_size].to_csv(output_directory + 'part2.csv', sep='\\t', index=False)\n",
    "df.iloc[2*part_size:].to_csv(output_directory + 'part3.csv', sep='\\t', index=False)\n",
    "\n",
    "# \n",
    "# combine files together after removing and filtering data\n",
    "df_part1 = pd.read_csv('../inputs/removingFile_part1.6.csv', sep='\\t', dtype=str)\n",
    "df_part2 = pd.read_csv('../inputs/removingFile_part2.6.csv', sep='\\t', dtype=str)\n",
    "df_part3 = pd.read_csv('../inputs/reticula_new/removingFile_part3.6.csv', sep='\\t', dtype=str)\n",
    "\n",
    "df_combined = pd.concat([df_part1, df_part2, df_part3], ignore_index=True)\n",
    "\n",
    "df_combined.to_csv(output_directory + 'combined_data_all_duplicate_restored.csv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee967b",
   "metadata": {},
   "source": [
    "## Filter Data Based On Comparison File (You need to manually generate the comparison file)\n",
    "\n",
    "This block was used to remove manually identified terms and may need to be revised based on your own needs. The final list of \n",
    "of samples is provided with the associated manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '/Users/kejiyuan/Desktop/RanceLab/reticula_new/renamed_data3.csv'\n",
    "output_file_path = '/Users/kejiyuan/Desktop/RanceLab/reticula_new/renamed_data4.csv'\n",
    "df = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/delete_these_smaller1.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_excel('/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/DeleteTheseTerms.xlsx')\n",
    "df_input = pd.read_csv(input_file_path, sep=',', dtype=str)\n",
    "\n",
    "def remove_rows_and_columns(df, column_name, keywords):\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
    "        return df\n",
    "    \n",
    "    if keywords[0] == '*':\n",
    "        # Delete rows where the column has non-empty values\n",
    "        condition = df[column_name].notna()\n",
    "        indices_to_delete = df[condition].index\n",
    "        df.drop(indices_to_delete, inplace=True)\n",
    "    else:\n",
    "        # Escape special characters in keywords\n",
    "        escaped_keywords = [re.escape(keyword) for keyword in keywords]\n",
    "        # Generate regular expression pattern\n",
    "        pattern = '|'.join(escaped_keywords)\n",
    "        # indices_to_delete = df[df[column_name].isin(keywords)].index\n",
    "        condition = df[column_name].str.contains(pattern, case=False, na=False, regex=True)\n",
    "\n",
    "        indices_to_delete = df[condition].index\n",
    "\n",
    "        df.drop(indices_to_delete, inplace=True)\n",
    "\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    df.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "columns_as_row = pd.DataFrame([df.columns.tolist()], columns=df.columns)\n",
    "# df = pd.concat([columns_as_row, df], ignore_index=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    rest_of_values = row.iloc[1:].dropna().values  \n",
    "\n",
    "    if len(rest_of_values) > 0:  \n",
    "        first_column_value = row.iloc[0] \n",
    "        print(index, df_input.shape, first_column_value, rest_of_values)\n",
    "        df_input = remove_rows_and_columns(df_input, first_column_value, rest_of_values)\n",
    "\n",
    "\n",
    "df_input.to_csv(output_file_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaab705",
   "metadata": {},
   "source": [
    "# Export a file based on key-value pairs of column names to facilitate manual deletion of useless data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b26c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a sequence and moves nulls to the end\n",
    "def move_nulls_to_end(series):\n",
    "    non_nulls = series.dropna()\n",
    "    nulls = series[series.isnull()]\n",
    "    return pd.concat([non_nulls, nulls]).reset_index(drop=True)\n",
    "\n",
    "def process_csv(input_file_path, output_file_path):\n",
    "    df = pd.read_csv(input_file_path, sep='\\t', dtype=str)\n",
    "    del df[df.columns[0]]\n",
    "\n",
    "    unique_data = {}\n",
    "    \n",
    "    # Iterate through each column and remove duplicate values\n",
    "    for column in df.columns:\n",
    "        unique_data[column] = df[column].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    unique_df = pd.DataFrame.from_dict(unique_data)\n",
    "\n",
    "    unique_df = unique_df.transpose()\n",
    "\n",
    "    sorted_df = unique_df.apply(move_nulls_to_end, axis=1)\n",
    "\n",
    "    sorted_df.to_csv(output_file_path, sep='\\t', index=True)\n",
    "\n",
    "# Call the function, which needs to be replaced with the actual file path\n",
    "input_file_path = '/Users/kejiyuan/Desktop/RanceLab/reticula_new/renamed_data4.csv'\n",
    "output_file_path = '/Users/kejiyuan/Desktop/RanceLab/reticula_new/key_val_pair.txt'\n",
    "process_csv(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc1243f",
   "metadata": {},
   "source": [
    "# Produce Project ID File in Bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b945c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory=\"/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/downloadFromRecount3/\"\n",
    "\n",
    "for file in \"$input_directory\"/*.txt; do\n",
    "    # Cut the first column and print each row with the filename\n",
    "    awk -v fname=\"$file\" '{print fname \"\\t\" $1}' \"$file\"\n",
    "done > \"/Users/kejiyuan/Desktop/RanceLab/reticula_new/SRR.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e83a02",
   "metadata": {},
   "source": [
    "# Merge Project ID Into Final File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830790c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "srr_df = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/SRR.csv', header=None, names=['path', 'SRR'], sep='\\t', quotechar='\"')\n",
    "recount3_selection_df = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/recount3_selection_2024-04-12.csv', sep=',', quotechar='\"')\n",
    "renamed_data4_df = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/renamed_data4.csv', sep='\\t', quotechar='\"')\n",
    "\n",
    "# Extract the project ID from the file path in SRR.csv\n",
    "\n",
    "srr_df['project_id'] = srr_df['path'].str.replace(r'/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/downloadFromRecount3//rse_gene_', '').str.replace(r'.txt', '')\n",
    "\n",
    "# Remove rows where SRR is 'rail_id'\n",
    "srr_df = srr_df[srr_df['SRR'] != 'rail_id']\n",
    "\n",
    "# Merge SRR.csv with recount3_selection.csv on the extracted project ID\n",
    "merged_df = pd.merge(srr_df, recount3_selection_df, left_on='project_id', right_on='project', how='left')\n",
    "\n",
    "# Merge the result with renamed_data4.csv on the SRR identifier\n",
    "final_df = pd.merge(merged_df, renamed_data4_df, on='SRR', how='left')\n",
    "\n",
    "# Select columns to keep from recount3_selection_2024-04-12.csv excluding 'project'\n",
    "columns_to_keep = ['organism', 'project_home', 'n_samples', 'study_title', 'study_abstract'] + list(renamed_data4_df.columns)\n",
    "final_df = final_df[columns_to_keep]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "final_df.to_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/renamed_data5.csv', index=False)\n",
    "\n",
    "print(\"Merging completed. Output saved as 'renamed_data5.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957fbe0",
   "metadata": {},
   "source": [
    "# Merge Columns Name Based on Specific File (If it is necessary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa275605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_df = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/combined_data_all_duplicate_restored.csv', sep='\\t')\n",
    "\n",
    "# Load the mapping file\n",
    "mapping_df = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/original_data/ColumnRenaming.txt', sep='\\t', dtype=str)\n",
    "mapping_df.loc[mapping_df['Old Column Name'] == 'Unnamed: 0', 'New Column'] = 'SRR'  # Make sure this mapping is correct\n",
    "\n",
    "# Apply renaming\n",
    "mapping_dict = dict(zip(mapping_df['Old Column Name'], mapping_df['New Column']))\n",
    "data_df.rename(columns=mapping_dict, inplace=True)\n",
    "\n",
    "# Make sure 'SRR' is the first column\n",
    "# We assume 'SRR' is already in the DataFrame from the renaming step\n",
    "columns = ['SRR'] + [col for col in data_df.columns if col != 'SRR']\n",
    "data_df = data_df[columns]\n",
    "\n",
    "# Define the function for merging columns\n",
    "def same_merge(x):\n",
    "    if len(x.dropna()) == 0:\n",
    "        return pd.NA\n",
    "    return ','.join(x.dropna().astype(str))\n",
    "\n",
    "# Apply merging and save\n",
    "grouped = data_df.groupby(by=data_df.columns, axis=1)\n",
    "data_df = grouped.apply(lambda x: x.apply(same_merge, axis=1))\n",
    "\n",
    "# Confirm 'SRR' is the first column and print final columns\n",
    "print(\"Final DataFrame columns:\", data_df.columns)\n",
    "\n",
    "# Save the results\n",
    "data_df.to_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/renamed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e817c",
   "metadata": {},
   "source": [
    "# Final Check On Data\n",
    "# You can delete by number of tissue and specific tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/rse_gene/CleanedSamplesGNN_v1.txt', sep='\\t')\n",
    "\n",
    "# Count the number of each issue\n",
    "tissue_counts = data['Major_tissue'].value_counts()\n",
    "\n",
    "# Delete all rows with number of tissue less than or equal to 20\n",
    "tissues_to_remove = tissue_counts[tissue_counts <= 20].index\n",
    "data = data[~data['Major_tissue'].isin(tissues_to_remove)]\n",
    "\n",
    "# Delete all rows of spleen\n",
    "data = data[data['Major_tissue'] != 'Spleen']\n",
    "\n",
    "data.to_csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/rse_gene/CleanedSamplesGNN_v2.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1c127e",
   "metadata": {},
   "source": [
    "# Produce rse_gene.Rdata File\n",
    "\n",
    "> This generates the input data for the GNN training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb66a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "recount_data <- read.csv(\"/Users/kejiyuan/Desktop/RanceLab/reticula_new/recount3_selection_2024-04-12.csv\")\n",
    "cleaned_data <- read.csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/rse_gene/CleanedSamplesGNN_v3.csv', sep='.')\n",
    "\n",
    "final_result <- NULL\n",
    "\n",
    "print(nrow(recount_data))\n",
    "\n",
    "for (i in 1:nrow(recount_data)) {\n",
    "      if (recount_data[i, 'study_title'] %in% cleaned_data$Title) {\n",
    "      print(paste(\"Current running\", i))\n",
    "      if (recount_data$n_samples[i] <= 600) {\n",
    "          tryCatch({\n",
    "            rse_gene <- recount3::create_rse_manual(\n",
    "              project = recount_data$project[i],\n",
    "              project_home = recount_data$project_home[i],\n",
    "              organism = recount_data$organism[i],\n",
    "              annotation = \"gencode_v23\",\n",
    "              type = \"gene\"\n",
    "            )\n",
    "\n",
    "            sample_list <- cleaned_data[,'SRR']\n",
    "            keep <- intersect(sample_list, colnames(rse_gene))\n",
    "            temp_rse_gene <- rse_gene[,keep]\n",
    "              \n",
    "            gene_order <- colData(temp_rse_gene)$external_id\n",
    "            cur_obj <- merge(colData(temp_rse_gene), cleaned_data, by.x=\"external_id\", by.y = \"SRR\", all.x=TRUE)\n",
    "            ordered_indices <- match(gene_order, cur_obj$external_id)\n",
    "            cur_obj <- cur_obj[ordered_indices, ]\n",
    "              \n",
    "            colData(temp_rse_gene) <- cur_obj\n",
    "            if (is.null(final_result)) {\n",
    "                final_result <- temp_rse_gene\n",
    "            } else {\n",
    "                final_result <- cbind(final_result, temp_rse_gene)\n",
    "            }\n",
    "          },\n",
    "          error = function(cond){\n",
    "              print(\"-----------------\")\n",
    "              print(recount_data$n_samples[i])\n",
    "              print(recount_data$project[i])\n",
    "              print(i)\n",
    "          }\n",
    "        )\n",
    "      }\n",
    "    }\n",
    "  \n",
    "}\n",
    "\n",
    "save(final_result, file = \"/Users/kejiyuan/Desktop/RanceLab/reticula_new/rse_gene/rse_gene.Rdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed6ecc",
   "metadata": {},
   "source": [
    "# Produce GEO_model_validation_rse_gene.Rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "recount_data <- read.csv(\"/Users/kejiyuan/Desktop/RanceLab/reticula_new/recount3_selection_2024-04-12.csv\")\n",
    "cleaned_data <- read.csv('/Users/kejiyuan/Desktop/RanceLab/reticula_new/rse_gene/GEO_model_validation.txt', sep='\\t')\n",
    "\n",
    "final_result <- NULL\n",
    "\n",
    "print(nrow(recount_data))\n",
    "needed_project_ids <- c('SRP131784', 'SRP090688', 'SRP161461', 'SRP075814', 'SRP049440')\n",
    "\n",
    "for (i in 1:nrow(recount_data)) {\n",
    "    print(paste(\"Current running\", i))\n",
    "    # Check if the current project ID is one of the needed ones\n",
    "    if (!(recount_data$project[i] %in% needed_project_ids)) {\n",
    "        next  # Skip the rest of this iteration if the project ID is not needed\n",
    "    }\n",
    "\n",
    "    tryCatch({\n",
    "        rse_gene <- recount3::create_rse_manual(\n",
    "          project = recount_data$project[i],\n",
    "          project_home = recount_data$project_home[i],\n",
    "          organism = recount_data$organism[i],\n",
    "          annotation = \"gencode_v23\",\n",
    "          type = \"gene\"\n",
    "        )\n",
    "\n",
    "        sample_list <- cleaned_data[,'SRR']\n",
    "        keep <- intersect(sample_list, colnames(rse_gene))\n",
    "        temp_rse_gene <- rse_gene[,keep]\n",
    "#         rownames(cleaned_data) <- cleaned_data$SRR\n",
    "        \n",
    "        gene_order <- colData(temp_rse_gene)$external_id\n",
    "        cur_obj <- merge(colData(temp_rse_gene), cleaned_data, by.x=\"external_id\", by.y = \"SRR\", all.x=TRUE)\n",
    "        ordered_indices <- match(gene_order, cur_obj$external_id)\n",
    "        cur_obj <- cur_obj[ordered_indices, ]\n",
    "        \n",
    "        colData(temp_rse_gene) <- cur_obj\n",
    "        if (is.null(final_result)) {\n",
    "            final_result <- temp_rse_gene\n",
    "        } else {\n",
    "            final_result <- cbind(final_result, temp_rse_gene)\n",
    "        }\n",
    "    },\n",
    "    error = function(cond){\n",
    "        print(\"-----------------\")\n",
    "        print(recount_data$n_samples[i])\n",
    "        print(recount_data$project[i])\n",
    "        print(i)\n",
    "    })\n",
    "\n",
    "}\n",
    "\n",
    "save(final_result, file = \"/Users/kejiyuan/Desktop/RanceLab/reticula_new/rse_gene/GEO_model_validation_rse_gene.Rdata\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72b64ab",
   "metadata": {},
   "source": [
    "# Generate reaction network mapping from Reactome data\n",
    "\n",
    "## Produce ReactionNetwork_Rel.txt\n",
    "\n",
    "1. Install Docker \n",
    "2. Find reactome/graph on dockerhub and running:\n",
    "    docker run -p 7474:7474 -p 7687:7687 -e NEO4J_dbms_memory_heap_maxSize=8g reactome/graphdb:latest\n",
    "3. The username is \"Neo4j\" and the password is \"admin\".\n",
    "4. Using the following two queries to get the data:\n",
    "    \"MATCH (r2:ReactionLikeEvent {speciesName:\"Mus musculus\"})-[:precedingEvent]->(r1:ReactionLikeEvent {speciesName:\"Mus musculus\"}) RETURN r1.stId as `Preceding Reaction`, r2.stId as `Following Reaction`\"\n",
    "    \n",
    "    \"MATCH (r1:ReactionLikeEvent {speciesName:\"Mus musculus\"})-[:output]->(PhysicalEntity)<-[:physicalEntity]-(CatalystActivity)<-[:catalystActivity]-(r2:ReactionLikeEvent {speciesName:\"Mus musculus\"}) RETURN r1.stId as `Preceding Reaction`,r2.stId as `Following Reaction`\"\n",
    "   \n",
    "5. Download teh result as Mouse1.csv and Mouse2.csv file.\n",
    "6. Using following code to integrate data together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = pd.read_csv(os.getcwd() + \"/Mouse1.csv\")\n",
    "file2 = pd.read_csv(os.getcwd() + \"/Mouse2.csv\")\n",
    "\n",
    "def insertCol(file):\n",
    "    file['Relationship'] = \"Preceding\"\n",
    "    col_names = file.columns.tolist()\n",
    "    new_col_order = [col_names[0], \"Relationship\"] + col_names[1:-1]\n",
    "    file = file[new_col_order]\n",
    "    return file\n",
    "\n",
    "file1 = insertCol(file1)\n",
    "file2 = insertCol(file2)\n",
    "\n",
    "merged_df = pd.concat([file1, file2], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"ReactionNetwork_Rel.txt\", sep=\"\\t\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82dc73e",
   "metadata": {},
   "source": [
    "## Produce ReactionToPathway_Rel.csv file\n",
    "\n",
    "1. Install Docker \n",
    "2. Find reactome/graph on dockerhub and running:\n",
    "    docker run -p 7474:7474 -p 7687:7687 -e NEO4J_dbms_memory_heap_maxSize=8g reactome/graphdb:latest\n",
    "3. The username is \"Neo4j\" and the password is \"admin\".\n",
    "4. Using following query to get the relationship between pathway and reaction\n",
    "    \"MATCH (p:Pathway {speciesName:\"Mus musculus\"})-[:hasEvent]->(r:ReactionLikeEvent)\n",
    "    RETURN p.stId as Pathway, r.stId as ReactionLikeEvent, r.displayName as Title\"\n",
    "5. Download teh result as ReactionToPathway_Rel.csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tox_reticula)",
   "language": "python",
   "name": "tox_reticula"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
