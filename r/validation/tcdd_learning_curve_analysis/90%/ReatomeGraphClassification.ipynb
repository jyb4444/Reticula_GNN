{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0c0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn.functional as nn_func\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GraphConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d50696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features exist: True, targets exist: True, edges exist: True  model exists: True\n"
     ]
    }
   ],
   "source": [
    "node_features_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/input/node_features030_2_time_course_90.txt'\n",
    "graph_targets_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/input/graph_targets030_time_course_90.txt'\n",
    "edges_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_training/input/edges.txt'\n",
    "model_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_training/GNN/trained_pytorch_model_rewired10_fold_full_dataset.pt'\n",
    "output_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/predictions030_time_course_90.tsv'\n",
    "sample_id_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/tcdd_sample_id030_time_course_90.txt'\n",
    "project_id_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/tcdd_project_id030_time_course_90.txt'\n",
    "gender_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/tcdd_gender030_time_course_90.txt'\n",
    "dose_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/tcdd_dose030_time_course_90.txt'\n",
    "# test graph_targets.txt, node_features.txt and edges.txt\n",
    "features_exist = op.exists(node_features_fn)\n",
    "targets_exist = op.exists(graph_targets_fn)\n",
    "edges_exist = op.exists(edges_fn)\n",
    "model_exists = op.exists(model_fn)\n",
    "\n",
    "print(f'features exist: {features_exist},'\n",
    "      f' targets exist: {targets_exist},'\n",
    "      f' edges exist: {edges_exist}',\n",
    "      f' model exists: {model_exists}')\n",
    "assert features_exist\n",
    "assert targets_exist\n",
    "assert edges_exist\n",
    "assert model_exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58f11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHANNELS = 1\n",
    "OUTPUT_CHANNELS = 26\n",
    "NEW_CHANNELS = 2\n",
    "HIDDEN_CHANNELS = 64\n",
    "BATCH_SIZE = 64\n",
    "BENCHMARKING = False\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c997a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.conv1 = GraphConv(INPUT_CHANNELS, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, OUTPUT_CHANNELS)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        #x = nn_func.dropout(x, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def read_reactome_graph(e_fn):\n",
    "    e_v1 = []\n",
    "    e_v2 = []\n",
    "\n",
    "    for line in open(e_fn, 'r'):\n",
    "        dt = line.split()\n",
    "        node1 = int(dt[0]) - 1  # subtracting to convert R idx to python idx\n",
    "        node2 = int(dt[1]) - 1  # \" \"\n",
    "        e_v1.append(node1)\n",
    "        e_v2.append(node2)\n",
    "\n",
    "    return e_v1, e_v2\n",
    "\n",
    "\n",
    "def build_reactome_graph_datalist(e_v1, e_v2, n_fn, g_fn, pid_fn, sid_fn, gen_fn, dose_fn):\n",
    "    edge_index = torch.tensor([e_v1, e_v2], dtype=torch.long)\n",
    "    feature_v = numpy.loadtxt(n_fn)\n",
    "    target_v = numpy.loadtxt(g_fn, dtype=float, delimiter=\",\")\n",
    "    projectID_v = numpy.loadtxt(pid_fn, dtype=str, delimiter=\"\\t\")\n",
    "    sampleID_v = numpy.loadtxt(sid_fn, dtype=str, delimiter=\"\\t\")\n",
    "    gender_v = numpy.loadtxt(gen_fn, dtype=str, delimiter=\"\\t\")\n",
    "    dose_v = numpy.loadtxt(dose_fn, dtype=str, delimiter=\"\\t\")\n",
    "    \n",
    "    binary_labels = (target_v > 0).astype(int)\n",
    "    \n",
    "    print(\"labels check:\")\n",
    "    for dose, label in zip(target_v[:10], binary_labels[:10]): \n",
    "        print(f\"dose: {dose}, label: {label}\")\n",
    "\n",
    "\n",
    "    d_list = []\n",
    "    for row_idx in range(len(feature_v)):\n",
    "        features = feature_v[row_idx, :]\n",
    "        x = torch.tensor(features, dtype=torch.float)\n",
    "        x = x.unsqueeze(1)\n",
    "#         y = torch.tensor([target_v[row_idx]])\n",
    "        y = torch.tensor([binary_labels[row_idx]], dtype=torch.long)\n",
    "        \n",
    "        pid = projectID_v[row_idx]\n",
    "        sid = sampleID_v[row_idx]\n",
    "        gen = gender_v[row_idx]\n",
    "        dose = dose_v[row_idx]\n",
    "        \n",
    "        d_list.append(Data(x=x, y=y, pid=pid, sid=sid, gen=gen, dose=dose, edge_index=edge_index))\n",
    "\n",
    "    return d_list\n",
    "\n",
    "\n",
    "def build_reactome_graph_loader(d_list, batch_size):\n",
    "    loader = DataLoader(d_list, batch_size=batch_size, shuffle=False)  # True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def train(loader, dv):\n",
    "    model.train()\n",
    "\n",
    "    correct = 0\n",
    "    for batch in loader:  # Iterate in batches over the training dataset.\n",
    "        batch.validate()\n",
    "        x = batch.x.to(dv)\n",
    "        e = batch.edge_index.to(dv)\n",
    "        b = batch.batch.to(dv)\n",
    "        y = batch.y.to(dv)\n",
    "\n",
    "        out = model(x, e, b)  # Perform a single forward pass.\n",
    "        loss = criterion(out, y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "def test(loader, dv):\n",
    "    model.eval()\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    project_ids = []\n",
    "    sample_ids = []\n",
    "    genders = []\n",
    "    doses = []\n",
    "    confidences = []\n",
    "    for batch in loader:  # Iterate in batches over the test dataset.\n",
    "        x = batch.x.to(dv)\n",
    "        e = batch.edge_index.to(dv)\n",
    "        b = batch.batch.to(dv)\n",
    "        y = batch.y.to(dv)\n",
    "        targets += torch.Tensor.tolist(y)\n",
    "        \n",
    "        project_ids += batch.pid\n",
    "        sample_ids += batch.sid\n",
    "        genders += batch.gen\n",
    "        doses += batch.dose\n",
    "        \n",
    "        out = model(x, e, b)  # Perform a single forward pass.\n",
    "        prob = torch.softmax(out, dim=1)\n",
    "        \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        predictions += torch.Tensor.tolist(pred)\n",
    "        confidences += torch.Tensor.tolist(prob)\n",
    "        \n",
    "    num_classes = len(confidences[0])\n",
    "\n",
    "    data_to_save = []\n",
    "    for i in range(len(targets)):\n",
    "        row = [project_ids[i], sample_ids[i], genders[i], doses[i], targets[i], predictions[i]] + confidences[i]\n",
    "        data_to_save.append(row)\n",
    "    data_to_save = numpy.array(data_to_save)\n",
    "    print(data_to_save)\n",
    "    \n",
    "    fmt = ['%s', '%s', '%s', '%s', '%s', '%s'] + ['%s' for _ in range(num_classes)]\n",
    "    \n",
    "    headers = ['project_ids', 'sample_ids', 'genders', 'doses', 'target', 'prediction'] + [f'confidence_class_{i}' for i in range(num_classes)]\n",
    "    numpy.savetxt(output_fn, data_to_save, fmt='\\t'.join(fmt), delimiter='\\t', header='\\t'.join(headers), comments='')\n",
    "        \n",
    "    ari = adjusted_rand_score(targets, predictions)\n",
    "    print(f'ari: {ari}')\n",
    "    return ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ab199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv1): GraphConv(1, 64)\n",
       "  (conv2): GraphConv(64, 64)\n",
       "  (conv3): GraphConv(64, 64)\n",
       "  (lin): Linear(in_features=64, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_key(self, old, new):\n",
    "    for _ in range(len(self)):\n",
    "        k, v = self.popitem(False)\n",
    "        self[new if old == k else k] = v\n",
    "\n",
    "\n",
    "(edge_v1, edge_v2) = read_reactome_graph(edges_fn)\n",
    "model = GNN(hidden_channels=HIDDEN_CHANNELS)\n",
    "device = cpu = torch.device('cpu')\n",
    "\n",
    "sd = torch.load(model_fn, map_location=device)\n",
    "change_key(sd, 'conv1.lin_l.weight', 'conv1.lin_rel.weight')\n",
    "change_key(sd, 'conv1.lin_l.bias', 'conv1.lin_rel.bias')\n",
    "change_key(sd, 'conv1.lin_r.weight', 'conv1.lin_root.weight')\n",
    "change_key(sd, 'conv2.lin_l.weight', 'conv2.lin_rel.weight')\n",
    "change_key(sd, 'conv2.lin_l.bias', 'conv2.lin_rel.bias')\n",
    "change_key(sd, 'conv2.lin_r.weight', 'conv2.lin_root.weight')\n",
    "change_key(sd, 'conv3.lin_l.weight', 'conv3.lin_rel.weight')\n",
    "change_key(sd, 'conv3.lin_l.bias', 'conv3.lin_rel.bias')\n",
    "change_key(sd, 'conv3.lin_r.weight', 'conv3.lin_root.weight')\n",
    "change_key(sd, 'lin.weight', 'lin.weight')\n",
    "change_key(sd, 'lin.bias', 'lin.bias')\n",
    "\n",
    "model.load_state_dict(sd)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4fba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace final layer with new shape matching new dataset\n",
    "model.lin = Linear(HIDDEN_CHANNELS, NEW_CHANNELS)\n",
    "\n",
    "model.conv1.lin_rel.weight.requires_grad = False\n",
    "model.conv1.lin_rel.bias.requires_grad = False\n",
    "model.conv1.lin_root.weight.requires_grad = False\n",
    "model.conv2.lin_rel.weight.requires_grad = False\n",
    "model.conv2.lin_rel.bias.requires_grad = False\n",
    "model.conv2.lin_root.weight.requires_grad = False\n",
    "model.conv3.lin_rel.weight.requires_grad = False\n",
    "model.conv3.lin_rel.bias.requires_grad = False\n",
    "model.conv3.lin_root.weight.requires_grad = False\n",
    "model.lin.weight.requires_grad = True\n",
    "model.lin.bias.requires_grad = True\n",
    "\n",
    "# for name, param in model.named_parameters(): print(name, param)\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3281a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels check:\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "dose: 0.0, label: 0\n",
      "122\n",
      "122\n",
      "Number of training graphs: 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/yuankeji/anaconda3/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Acc: 0.9918032786885246\n",
      "Epoch: 1, Train Acc: 0.9918032786885246\n",
      "Epoch: 2, Train Acc: 0.9836065573770492\n",
      "Epoch: 3, Train Acc: 0.9836065573770492\n",
      "Epoch: 4, Train Acc: 0.9836065573770492\n",
      "Epoch: 5, Train Acc: 0.9836065573770492\n",
      "Epoch: 6, Train Acc: 0.9836065573770492\n",
      "Epoch: 7, Train Acc: 0.9836065573770492\n",
      "Epoch: 8, Train Acc: 0.9836065573770492\n",
      "Epoch: 9, Train Acc: 0.9836065573770492\n",
      "Epoch: 10, Train Acc: 0.9836065573770492\n",
      "Epoch: 11, Train Acc: 0.9918032786885246\n",
      "Epoch: 12, Train Acc: 0.9918032786885246\n",
      "Epoch: 13, Train Acc: 0.9918032786885246\n",
      "Epoch: 14, Train Acc: 0.9918032786885246\n",
      "Epoch: 15, Train Acc: 0.9918032786885246\n",
      "Epoch: 16, Train Acc: 0.9918032786885246\n",
      "Epoch: 17, Train Acc: 0.9918032786885246\n",
      "Epoch: 18, Train Acc: 0.9918032786885246\n",
      "Epoch: 19, Train Acc: 0.9918032786885246\n",
      "Epoch: 20, Train Acc: 0.9918032786885246\n",
      "Epoch: 21, Train Acc: 0.9918032786885246\n",
      "Epoch: 22, Train Acc: 0.9918032786885246\n",
      "Epoch: 23, Train Acc: 0.9918032786885246\n",
      "Epoch: 24, Train Acc: 0.9918032786885246\n",
      "Epoch: 25, Train Acc: 0.9918032786885246\n",
      "Epoch: 26, Train Acc: 0.9918032786885246\n",
      "Epoch: 27, Train Acc: 0.9918032786885246\n",
      "Epoch: 28, Train Acc: 0.9918032786885246\n",
      "Epoch: 29, Train Acc: 0.9918032786885246\n",
      "Epoch: 30, Train Acc: 0.9918032786885246\n",
      "Epoch: 31, Train Acc: 0.9918032786885246\n",
      "Epoch: 32, Train Acc: 0.9918032786885246\n",
      "Epoch: 33, Train Acc: 0.9918032786885246\n",
      "Epoch: 34, Train Acc: 0.9918032786885246\n",
      "Epoch: 35, Train Acc: 0.9918032786885246\n",
      "Epoch: 36, Train Acc: 0.9918032786885246\n",
      "Epoch: 37, Train Acc: 0.9918032786885246\n",
      "Epoch: 38, Train Acc: 0.9918032786885246\n",
      "Epoch: 39, Train Acc: 0.9918032786885246\n",
      "Epoch: 40, Train Acc: 0.9918032786885246\n",
      "Epoch: 41, Train Acc: 0.9918032786885246\n",
      "Epoch: 42, Train Acc: 0.9918032786885246\n",
      "Epoch: 43, Train Acc: 0.9918032786885246\n",
      "Epoch: 44, Train Acc: 0.9918032786885246\n",
      "Epoch: 45, Train Acc: 0.9918032786885246\n",
      "Epoch: 46, Train Acc: 0.9918032786885246\n",
      "Epoch: 47, Train Acc: 0.9918032786885246\n",
      "Epoch: 48, Train Acc: 0.9918032786885246\n",
      "Epoch: 49, Train Acc: 0.9918032786885246\n",
      "Epoch: 50, Train Acc: 0.9918032786885246\n",
      "Epoch: 51, Train Acc: 0.9918032786885246\n",
      "Epoch: 52, Train Acc: 0.9918032786885246\n",
      "Epoch: 53, Train Acc: 0.9918032786885246\n",
      "Epoch: 54, Train Acc: 0.9918032786885246\n",
      "Epoch: 55, Train Acc: 0.9918032786885246\n",
      "Epoch: 56, Train Acc: 0.9918032786885246\n",
      "Epoch: 57, Train Acc: 0.9918032786885246\n",
      "Epoch: 58, Train Acc: 0.9918032786885246\n",
      "Epoch: 59, Train Acc: 0.9918032786885246\n",
      "Epoch: 60, Train Acc: 0.9918032786885246\n",
      "Epoch: 61, Train Acc: 0.9918032786885246\n",
      "Epoch: 62, Train Acc: 0.9918032786885246\n",
      "Epoch: 63, Train Acc: 0.9918032786885246\n",
      "Epoch: 64, Train Acc: 0.9918032786885246\n",
      "Epoch: 65, Train Acc: 0.9918032786885246\n",
      "Epoch: 66, Train Acc: 0.9918032786885246\n",
      "Epoch: 67, Train Acc: 0.9918032786885246\n",
      "Epoch: 68, Train Acc: 0.9918032786885246\n",
      "Epoch: 69, Train Acc: 0.9918032786885246\n",
      "Epoch: 70, Train Acc: 0.9918032786885246\n",
      "Epoch: 71, Train Acc: 0.9918032786885246\n",
      "Epoch: 72, Train Acc: 0.9918032786885246\n",
      "Epoch: 73, Train Acc: 0.9918032786885246\n",
      "Epoch: 74, Train Acc: 0.9918032786885246\n",
      "Epoch: 75, Train Acc: 0.9918032786885246\n",
      "Epoch: 76, Train Acc: 0.9918032786885246\n",
      "Epoch: 77, Train Acc: 0.9918032786885246\n",
      "Epoch: 78, Train Acc: 0.9918032786885246\n",
      "Epoch: 79, Train Acc: 0.9918032786885246\n",
      "Epoch: 80, Train Acc: 0.9918032786885246\n",
      "Epoch: 81, Train Acc: 0.9918032786885246\n",
      "Epoch: 82, Train Acc: 0.9918032786885246\n",
      "Epoch: 83, Train Acc: 0.9918032786885246\n",
      "Epoch: 84, Train Acc: 0.9918032786885246\n",
      "Epoch: 85, Train Acc: 0.9918032786885246\n",
      "Epoch: 86, Train Acc: 0.9918032786885246\n",
      "Epoch: 87, Train Acc: 0.9918032786885246\n",
      "Epoch: 88, Train Acc: 0.9918032786885246\n",
      "Epoch: 89, Train Acc: 0.9918032786885246\n",
      "Epoch: 90, Train Acc: 0.9918032786885246\n",
      "Epoch: 91, Train Acc: 0.9918032786885246\n",
      "Epoch: 92, Train Acc: 0.9918032786885246\n",
      "Epoch: 93, Train Acc: 0.9918032786885246\n",
      "Epoch: 94, Train Acc: 0.9918032786885246\n",
      "Epoch: 95, Train Acc: 0.9918032786885246\n",
      "Epoch: 96, Train Acc: 0.9918032786885246\n",
      "Epoch: 97, Train Acc: 0.9918032786885246\n",
      "Epoch: 98, Train Acc: 0.9918032786885246\n",
      "Epoch: 99, Train Acc: 0.9918032786885246\n",
      "Epoch: 100, Train Acc: 0.9918032786885246\n",
      "Epoch: 101, Train Acc: 0.9918032786885246\n",
      "Epoch: 102, Train Acc: 0.9918032786885246\n",
      "Epoch: 103, Train Acc: 0.9918032786885246\n",
      "Epoch: 104, Train Acc: 0.9918032786885246\n",
      "Epoch: 105, Train Acc: 0.9918032786885246\n",
      "Epoch: 106, Train Acc: 0.9918032786885246\n",
      "Epoch: 107, Train Acc: 0.9918032786885246\n",
      "Epoch: 108, Train Acc: 0.9918032786885246\n",
      "Epoch: 109, Train Acc: 0.9918032786885246\n",
      "Epoch: 110, Train Acc: 0.9918032786885246\n",
      "Epoch: 111, Train Acc: 0.9918032786885246\n",
      "Epoch: 112, Train Acc: 0.9918032786885246\n",
      "Epoch: 113, Train Acc: 0.9918032786885246\n",
      "Epoch: 114, Train Acc: 0.9918032786885246\n",
      "Epoch: 115, Train Acc: 0.9918032786885246\n",
      "Epoch: 116, Train Acc: 0.9918032786885246\n",
      "Epoch: 117, Train Acc: 0.9918032786885246\n",
      "Epoch: 118, Train Acc: 0.9918032786885246\n",
      "Epoch: 119, Train Acc: 0.9918032786885246\n",
      "Epoch: 120, Train Acc: 0.9918032786885246\n",
      "Epoch: 121, Train Acc: 0.9918032786885246\n",
      "Epoch: 122, Train Acc: 0.9918032786885246\n",
      "Epoch: 123, Train Acc: 0.9918032786885246\n",
      "Epoch: 124, Train Acc: 0.9918032786885246\n",
      "Epoch: 125, Train Acc: 0.9918032786885246\n",
      "Epoch: 126, Train Acc: 0.9918032786885246\n",
      "Epoch: 127, Train Acc: 0.9918032786885246\n",
      "Epoch: 128, Train Acc: 0.9918032786885246\n",
      "Epoch: 129, Train Acc: 0.9918032786885246\n",
      "Epoch: 130, Train Acc: 0.9918032786885246\n",
      "Epoch: 131, Train Acc: 0.9918032786885246\n",
      "Epoch: 132, Train Acc: 0.9918032786885246\n",
      "Epoch: 133, Train Acc: 0.9918032786885246\n",
      "Epoch: 134, Train Acc: 0.9918032786885246\n",
      "Epoch: 135, Train Acc: 0.9918032786885246\n",
      "Epoch: 136, Train Acc: 0.9918032786885246\n",
      "Epoch: 137, Train Acc: 0.9918032786885246\n",
      "Epoch: 138, Train Acc: 0.9918032786885246\n",
      "Epoch: 139, Train Acc: 0.9918032786885246\n",
      "Epoch: 140, Train Acc: 0.9918032786885246\n",
      "Epoch: 141, Train Acc: 0.9918032786885246\n",
      "Epoch: 142, Train Acc: 0.9918032786885246\n",
      "Epoch: 143, Train Acc: 0.9918032786885246\n",
      "Epoch: 144, Train Acc: 0.9918032786885246\n",
      "Epoch: 145, Train Acc: 0.9918032786885246\n",
      "Epoch: 146, Train Acc: 0.9918032786885246\n",
      "Epoch: 147, Train Acc: 0.9918032786885246\n",
      "Epoch: 148, Train Acc: 0.9918032786885246\n",
      "Epoch: 149, Train Acc: 0.9918032786885246\n",
      "Epoch: 150, Train Acc: 1.0\n",
      "[['\"SRP161461\"' '\"SRR7817613\"' '\"male\"' '0' '0' '0' '0.9997934699058533'\n",
      "  '0.00020655340631492436']\n",
      " ['\"SRP161461\"' '\"SRR7817625\"' '\"male\"' '0' '0' '0' '0.9998555183410645'\n",
      "  '0.00014445478154812008']\n",
      " ['\"SRP075814\"' '\"SRR3593523\"' '\"female\"' '0' '0' '0'\n",
      "  '0.8867828249931335' '0.11321718245744705']\n",
      " ['\"SRP161461\"' '\"SRR7817676\"' '\"male\"' '0' '0' '0' '0.9982039928436279'\n",
      "  '0.0017959404503926635']\n",
      " ['\"SRP090688\"' '\"SRR4317609\"' '\"male\"' '0' '0' '0' '0.9735321402549744'\n",
      "  '0.02646782621741295']\n",
      " ['\"SRP161461\"' '\"SRR7817660\"' '\"male\"' '0' '0' '0' '0.9983869791030884'\n",
      "  '0.0016129952855408192']\n",
      " ['\"SRP161461\"' '\"SRR7817664\"' '\"male\"' '0' '0' '0' '0.9994305968284607'\n",
      "  '0.0005693198763765395']\n",
      " ['\"SRP161461\"' '\"SRR7817648\"' '\"male\"' '0' '0' '0' '0.9997161030769348'\n",
      "  '0.00028385926270857453']\n",
      " ['\"SRP161461\"' '\"SRR7817698\"' '\"male\"' '0' '0' '0' '0.9997767806053162'\n",
      "  '0.00022326517500914633']\n",
      " ['\"SRP161461\"' '\"SRR7817651\"' '\"male\"' '0' '0' '0' '0.9997450709342957'\n",
      "  '0.0002548836637288332']\n",
      " ['\"SRP090688\"' '\"SRR4317610\"' '\"male\"' '0' '0' '0' '0.9787862300872803'\n",
      "  '0.02121380716562271']\n",
      " ['\"SRP161461\"' '\"SRR7817611\"' '\"male\"' '0' '0' '0' '0.9988330006599426'\n",
      "  '0.0011669992236420512']\n",
      " ['\"SRP161461\"' '\"SRR7817652\"' '\"male\"' '0' '0' '0' '0.9996861219406128'\n",
      "  '0.0003138784668408334']\n",
      " ['\"SRP161461\"' '\"SRR7817612\"' '\"male\"' '0' '0' '0' '0.9990930557250977'\n",
      "  '0.0009069493389688432']\n",
      " ['\"SRP161461\"' '\"SRR7817638\"' '\"male\"' '0' '0' '0' '0.9995930790901184'\n",
      "  '0.00040690440800972283']\n",
      " ['\"SRP049440\"' '\"SRR1636586\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9869815707206726' '0.013018443249166012']\n",
      " ['\"SRP161461\"' '\"SRR7817637\"' '\"male\"' '0' '0' '0' '0.99937504529953'\n",
      "  '0.0006250273436307907']\n",
      " ['\"SRP161461\"' '\"SRR7817615\"' '\"male\"' '0' '0' '0' '0.9995348453521729'\n",
      "  '0.0004652039788197726']\n",
      " ['\"SRP049440\"' '\"SRR1636593\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9958764314651489' '0.004123488441109657']\n",
      " ['\"SRP161461\"' '\"SRR7817674\"' '\"male\"' '0' '0' '0' '0.9915394186973572'\n",
      "  '0.008460614830255508']\n",
      " ['\"SRP090688\"' '\"SRR4317611\"' '\"male\"' '0' '0' '0' '0.9646103978157043'\n",
      "  '0.03538956865668297']\n",
      " ['\"SRP161461\"' '\"SRR7817639\"' '\"male\"' '0' '0' '0' '0.9981454610824585'\n",
      "  '0.0018546001520007849']\n",
      " ['\"SRP161461\"' '\"SRR7817673\"' '\"male\"' '0' '0' '0' '0.9808756113052368'\n",
      "  '0.019124360755085945']\n",
      " ['\"SRP161461\"' '\"SRR7817636\"' '\"male\"' '0' '0' '0' '0.9991716146469116'\n",
      "  '0.0008284327341243625']\n",
      " ['\"SRP161461\"' '\"SRR7817696\"' '\"male\"' '0' '0' '0' '0.9997517466545105'\n",
      "  '0.0002481992996763438']\n",
      " ['\"SRP161461\"' '\"SRR7817688\"' '\"male\"' '0' '0' '0' '0.999841570854187'\n",
      "  '0.00015843244909774512']\n",
      " ['\"SRP161461\"' '\"SRR7817661\"' '\"male\"' '0' '0' '0' '0.9997273087501526'\n",
      "  '0.00027266860706731677']\n",
      " ['\"SRP161461\"' '\"SRR7817614\"' '\"male\"' '0' '0' '0' '0.9996961355209351'\n",
      "  '0.00030385598074644804']\n",
      " ['\"SRP161461\"' '\"SRR7817675\"' '\"male\"' '0' '0' '0' '0.9988183379173279'\n",
      "  '0.0011816414771601558']\n",
      " ['\"SRP090688\"' '\"SRR4317612\"' '\"male\"' '0' '0' '0' '0.979739248752594'\n",
      "  '0.020260680466890335']\n",
      " ['\"SRP161461\"' '\"SRR7817685\"' '\"male\"' '0' '0' '0' '0.9995525479316711'\n",
      "  '0.0004473846929613501']\n",
      " ['\"SRP049440\"' '\"SRR1636594\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9922453761100769' '0.007754663471132517']\n",
      " ['\"SRP161461\"' '\"SRR7817616\"' '\"male\"' '0' '0' '0' '0.9992687106132507'\n",
      "  '0.0007313068490475416']\n",
      " ['\"SRP161461\"' '\"SRR7817663\"' '\"male\"' '0' '0' '0' '0.9994694590568542'\n",
      "  '0.0005305800586938858']\n",
      " ['\"SRP161461\"' '\"SRR7817697\"' '\"male\"' '0' '0' '0' '0.9995989203453064'\n",
      "  '0.00040108186658471823']\n",
      " ['\"SRP161461\"' '\"SRR7817699\"' '\"male\"' '0' '0' '0' '0.9997851252555847'\n",
      "  '0.00021490432845894247']\n",
      " ['\"SRP090688\"' '\"SRR4317608\"' '\"male\"' '0' '0' '0' '0.9749026298522949'\n",
      "  '0.025097347795963287']\n",
      " ['\"SRP161461\"' '\"SRR7817628\"' '\"male\"' '0' '0' '0' '0.9997267127037048'\n",
      "  '0.00027332009631209075']\n",
      " ['\"SRP161461\"' '\"SRR7817647\"' '\"male\"' '0' '0' '0' '0.9998307228088379'\n",
      "  '0.00016923912335187197']\n",
      " ['\"SRP161461\"' '\"SRR7817662\"' '\"male\"' '0' '0' '0' '0.9996546506881714'\n",
      "  '0.0003453970712143928']\n",
      " ['\"SRP161461\"' '\"SRR7817649\"' '\"male\"' '0' '0' '0' '0.9996147155761719'\n",
      "  '0.0003852283116430044']\n",
      " ['\"SRP161461\"' '\"SRR7817683\"' '\"male\"' '0' '0' '0' '0.9998766183853149'\n",
      "  '0.00012331316247582436']\n",
      " ['\"SRP161461\"' '\"SRR7817650\"' '\"male\"' '0' '0' '0' '0.9996932744979858'\n",
      "  '0.00030675300513394177']\n",
      " ['\"SRP090688\"' '\"SRR4317607\"' '\"male\"' '0' '0' '0' '0.9804756045341492'\n",
      "  '0.0195243451744318']\n",
      " ['\"SRP049440\"' '\"SRR1636592\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9962173104286194' '0.003782691201195121']\n",
      " ['\"SRP049440\"' '\"SRR1636590\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9917634725570679' '0.008236604742705822']\n",
      " ['\"SRP161461\"' '\"SRR7817672\"' '\"male\"' '0' '0' '0' '0.914836585521698'\n",
      "  '0.0851634070277214']\n",
      " ['\"SRP049440\"' '\"SRR1636591\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9851240515708923' '0.014875936321914196']\n",
      " ['\"SRP161461\"' '\"SRR7817640\"' '\"male\"' '0' '0' '0' '0.9982722997665405'\n",
      "  '0.0017276781145483255']\n",
      " ['\"SRP161461\"' '\"SRR7817623\"' '\"male\"' '0' '0' '0' '0.9986549615859985'\n",
      "  '0.0013450229307636619']\n",
      " ['\"SRP075814\"' '\"SRR3593526\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9835528135299683' '0.016447219997644424']\n",
      " ['\"SRP049440\"' '\"SRR1636588\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9896807074546814' '0.010319231078028679']\n",
      " ['\"SRP075814\"' '\"SRR3593525\"' '\"female\"' '0' '0' '0' '0.995009183883667'\n",
      "  '0.004990805871784687']\n",
      " ['\"SRP161461\"' '\"SRR7817626\"' '\"male\"' '0' '0' '0' '0.9998557567596436'\n",
      "  '0.00014421227388083935']\n",
      " ['\"SRP161461\"' '\"SRR7817684\"' '\"male\"' '0' '0' '0' '0.999738872051239'\n",
      "  '0.0002611178788356483']\n",
      " ['\"SRP161461\"' '\"SRR7817624\"' '\"male\"' '0' '0' '0' '0.9991401433944702'\n",
      "  '0.0008597856503911316']\n",
      " ['\"SRP161461\"' '\"SRR7817686\"' '\"male\"' '0' '0' '0' '0.9993959665298462'\n",
      "  '0.000604032538831234']\n",
      " ['\"SRP161461\"' '\"SRR7817700\"' '\"male\"' '0' '0' '0' '0.9997220635414124'\n",
      "  '0.0002779238857328892']\n",
      " ['\"SRP075814\"' '\"SRR3593527\"' '\"female\"' '0' '0' '0'\n",
      "  '0.9861792325973511' '0.013820799067616463']\n",
      " ['\"SRP161461\"' '\"SRR7817659\"' '\"male\"' '0' '0' '0' '0.9984380602836609'\n",
      "  '0.0015618926845490932']\n",
      " ['\"SRP075814\"' '\"SRR3593524\"' '\"female\"' '0' '0' '0' '0.993198573589325'\n",
      "  '0.006801369599997997']\n",
      " ['\"SRP161461\"' '\"SRR7817620\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0016240723198279738' '0.9983758926391602']\n",
      " ['\"SRP161461\"' '\"SRR7817646\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00019880232866853476' '0.9998012185096741']\n",
      " ['\"SRP161461\"' '\"SRR7817704\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0008850075537338853' '0.9991149306297302']\n",
      " ['\"SRP161461\"' '\"SRR7817642\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00030138774309307337' '0.9996986389160156']\n",
      " ['\"SRP090688\"' '\"SRR4317657\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00038747317739762366' '0.9996125102043152']\n",
      " ['\"SRP161461\"' '\"SRR7817644\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0027893264777958393' '0.997210681438446']\n",
      " ['\"SRP161461\"' '\"SRR7817665\"' '\"male\"' '30' '1' '1'\n",
      "  '9.3421149358619e-05' '0.9999065399169922']\n",
      " ['\"SRP161461\"' '\"SRR7817667\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0007945782272145152' '0.9992054104804993']\n",
      " ['\"SRP161461\"' '\"SRR7817691\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0005837768549099565' '0.9994162321090698']\n",
      " ['\"SRP161461\"' '\"SRR7817668\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0002693717833608389' '0.99973064661026']\n",
      " ['\"SRP049440\"' '\"SRR1636672\"' '\"female\"' '30' '1' '1'\n",
      "  '0.022677579894661903' '0.9773224592208862']\n",
      " ['\"SRP161461\"' '\"SRR7817621\"' '\"male\"' '30' '1' '1'\n",
      "  '1.4099551663093735e-05' '0.999985933303833']\n",
      " ['\"SRP161461\"' '\"SRR7817631\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00020022832904942334' '0.9997997879981995']\n",
      " ['\"SRP161461\"' '\"SRR7817619\"' '\"male\"' '30' '1' '1'\n",
      "  '0.003148194868117571' '0.9968518614768982']\n",
      " ['\"SRP161461\"' '\"SRR7817701\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00036226509837433696' '0.9996377229690552']\n",
      " ['\"SRP161461\"' '\"SRR7817622\"' '\"male\"' '30' '1' '1'\n",
      "  '1.3567950190918054e-05' '0.9999864101409912']\n",
      " ['\"SRP161461\"' '\"SRR7817705\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0025119008496403694' '0.9974881410598755']\n",
      " ['\"SRP161461\"' '\"SRR7817680\"' '\"male\"' '30' '1' '1'\n",
      "  '0.001471382100135088' '0.9985285997390747']\n",
      " ['\"SRP049440\"' '\"SRR1636674\"' '\"female\"' '30' '1' '1'\n",
      "  '0.015584883280098438' '0.9844151139259338']\n",
      " ['\"SRP090688\"' '\"SRR4317656\"' '\"male\"' '30' '1' '1'\n",
      "  '5.224160850048065e-05' '0.9999477863311768']\n",
      " ['\"SRP161461\"' '\"SRR7817653\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0010574788320809603' '0.9989425539970398']\n",
      " ['\"SRP049440\"' '\"SRR1636676\"' '\"female\"' '30' '1' '1'\n",
      "  '0.01855502836406231' '0.9814448952674866']\n",
      " ['\"SRP075814\"' '\"SRR3593580\"' '\"female\"' '30' '1' '1'\n",
      "  '0.0005128705524839461' '0.9994871616363525']\n",
      " ['\"SRP161461\"' '\"SRR7817658\"' '\"male\"' '30' '1' '1'\n",
      "  '3.79003795387689e-05' '0.9999620914459229']\n",
      " ['\"SRP161461\"' '\"SRR7817632\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00014537200331687927' '0.999854564666748']\n",
      " ['\"SRP090688\"' '\"SRR4317660\"' '\"male\"' '30' '1' '1'\n",
      "  '4.0524642827222124e-05' '0.9999594688415527']\n",
      " ['\"SRP161461\"' '\"SRR7817669\"' '\"male\"' '30' '1' '1'\n",
      "  '4.3431384256109595e-05' '0.9999566078186035']\n",
      " ['\"SRP049440\"' '\"SRR1636671\"' '\"female\"' '30' '1' '1'\n",
      "  '0.040677543729543686' '0.959322452545166']\n",
      " ['\"SRP075814\"' '\"SRR3593578\"' '\"female\"' '30' '1' '1'\n",
      "  '0.001891924999654293' '0.9981080293655396']\n",
      " ['\"SRP161461\"' '\"SRR7817656\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00014706670481245965' '0.9998528957366943']\n",
      " ['\"SRP161461\"' '\"SRR7817655\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0001428515970474109' '0.9998571872711182']\n",
      " ['\"SRP090688\"' '\"SRR4317658\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0003749406896531582' '0.9996250867843628']\n",
      " ['\"SRP161461\"' '\"SRR7817693\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0002076354721793905' '0.9997923970222473']\n",
      " ['\"SRP161461\"' '\"SRR7817694\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0005017987568862736' '0.9994981288909912']\n",
      " ['\"SRP075814\"' '\"SRR3593574\"' '\"female\"' '30' '1' '1'\n",
      "  '0.0006718438817188144' '0.9993281364440918']\n",
      " ['\"SRP161461\"' '\"SRR7817633\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0006071623647585511' '0.9993928670883179']\n",
      " ['\"SRP161461\"' '\"SRR7817629\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0001196464872919023' '0.999880313873291']\n",
      " ['\"SRP161461\"' '\"SRR7817641\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0004270678327884525' '0.9995729327201843']\n",
      " ['\"SRP075814\"' '\"SRR3593573\"' '\"female\"' '30' '1' '1'\n",
      "  '0.0004942561499774456' '0.9995057582855225']\n",
      " ['\"SRP161461\"' '\"SRR7817657\"' '\"male\"' '30' '1' '1'\n",
      "  '5.4182302847038954e-05' '0.9999457597732544']\n",
      " ['\"SRP161461\"' '\"SRR7817643\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0009201799402944744' '0.9990798234939575']\n",
      " ['\"SRP075814\"' '\"SRR3593579\"' '\"female\"' '30' '1' '1'\n",
      "  '0.0020849998109042645' '0.9979149699211121']\n",
      " ['\"SRP161461\"' '\"SRR7817702\"' '\"male\"' '30' '1' '1'\n",
      "  '0.000482689356431365' '0.9995173215866089']\n",
      " ['\"SRP161461\"' '\"SRR7817666\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00014825207472313195' '0.9998517036437988']\n",
      " ['\"SRP049440\"' '\"SRR1636675\"' '\"female\"' '30' '1' '1'\n",
      "  '0.49868708848953247' '0.5013129115104675']\n",
      " ['\"SRP161461\"' '\"SRR7817692\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0002893928322009742' '0.9997106194496155']\n",
      " ['\"SRP075814\"' '\"SRR3593577\"' '\"female\"' '30' '1' '1'\n",
      "  '0.012947868555784225' '0.9870522022247314']\n",
      " ['\"SRP161461\"' '\"SRR7817681\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0008338213083334267' '0.9991662502288818']\n",
      " ['\"SRP161461\"' '\"SRR7817678\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00044991783215664327' '0.9995500445365906']\n",
      " ['\"SRP161461\"' '\"SRR7817703\"' '\"male\"' '30' '1' '1'\n",
      "  '0.001155714737251401' '0.9988442659378052']\n",
      " ['\"SRP161461\"' '\"SRR7817690\"' '\"male\"' '30' '1' '1'\n",
      "  '0.00041947292629629374' '0.9995805621147156']\n",
      " ['\"SRP161461\"' '\"SRR7817634\"' '\"male\"' '30' '1' '1'\n",
      "  '0.000674954557325691' '0.9993250370025635']\n",
      " ['\"SRP161461\"' '\"SRR7817617\"' '\"male\"' '30' '1' '1'\n",
      "  '1.480514129070798e-07' '0.9999998807907104']\n",
      " ['\"SRP161461\"' '\"SRR7817706\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0011704129865393043' '0.9988295435905457']\n",
      " ['\"SRP075814\"' '\"SRR3593575\"' '\"female\"' '30' '1' '1'\n",
      "  '0.0003144487563986331' '0.999685525894165']\n",
      " ['\"SRP161461\"' '\"SRR7817689\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0007594230701215565' '0.9992406368255615']\n",
      " ['\"SRP049440\"' '\"SRR1636673\"' '\"female\"' '30' '1' '1'\n",
      "  '0.009240495972335339' '0.9907594919204712']\n",
      " ['\"SRP090688\"' '\"SRR4317659\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0001000286138150841' '0.9998999834060669']\n",
      " ['\"SRP161461\"' '\"SRR7817670\"' '\"male\"' '30' '1' '1'\n",
      "  '3.996935629402287e-05' '0.9999600648880005']\n",
      " ['\"SRP161461\"' '\"SRR7817630\"' '\"male\"' '30' '1' '1'\n",
      "  '4.2923205910483375e-05' '0.9999570846557617']\n",
      " ['\"SRP161461\"' '\"SRR7817679\"' '\"male\"' '30' '1' '1'\n",
      "  '0.0009627334075048566' '0.9990372657775879']]\n",
      "ari: 1.0\n",
      "test_ari: 1.0\n",
      "model saved as /mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/tuned_pytorch_tcdd_model030_time_course_90.pt\n"
     ]
    }
   ],
   "source": [
    "data_list = build_reactome_graph_datalist(edge_v1, edge_v2, node_features_fn, graph_targets_fn, project_id_fn, sample_id_fn, gender_fn, dose_fn)\n",
    "print(len(data_list))\n",
    "# retrain model for fine tuning transfer learning\n",
    "train_data_list = data_list  # all data\n",
    "print(len(train_data_list))\n",
    "print(f'Number of training graphs: {len(train_data_list)}')\n",
    "train_data_loader = build_reactome_graph_loader(train_data_list, BATCH_SIZE)\n",
    "for epoch in range(EPOCHS):\n",
    "    train(train_data_loader, device)\n",
    "    train_acc = train(train_data_loader, device)\n",
    "    print(f'Epoch: {epoch}, Train Acc: {train_acc}')\n",
    "    if train_acc == 1.0:\n",
    "        break\n",
    "\n",
    "final_ari = test(train_data_loader, device)\n",
    "print(f'test_ari: {final_ari}')\n",
    "\n",
    "model_save_name = f'tuned_pytorch_tcdd_model030_time_course_90.pt'\n",
    "path = f'/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/learning_curve_analysis/output/{model_save_name}'\n",
    "torch.save(model.state_dict(), path)\n",
    "print(f'model saved as {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125595a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
