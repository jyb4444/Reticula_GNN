{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc60abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import time\n",
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict\n",
    "from IPython.display import Javascript\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from captum.attr import Saliency, IntegratedGradients\n",
    "from torch_geometric.nn import GraphConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd8a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features exist: True, targets exist: True, edges exist: True  model exists: True\n"
     ]
    }
   ],
   "source": [
    "node_features_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/input/node_features030.txt'\n",
    "graph_targets_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/input/graph_targets030.txt'\n",
    "edges_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_training/input/edges.txt'\n",
    "model_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/tuned_pytorch_tcdd_model030.pt'\n",
    "output_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/predictions030.tsv'\n",
    "transformed_targets_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/transformed_targets030.txt'\n",
    "inverted_targets_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/inverted_targets030.txt'\n",
    "\n",
    "features_exist = op.exists(node_features_fn)\n",
    "targets_exist = op.exists(graph_targets_fn)\n",
    "edges_exist = op.exists(edges_fn)\n",
    "model_exists = op.exists(model_fn)\n",
    "\n",
    "print(f'features exist: {features_exist},'\n",
    "      f' targets exist: {targets_exist},'\n",
    "      f' edges exist: {edges_exist}',\n",
    "      f' model exists: {model_exists}')\n",
    "assert features_exist\n",
    "assert targets_exist\n",
    "assert edges_exist\n",
    "assert model_exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a888df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic numbers\n",
    "INPUT_CHANNELS = 1\n",
    "OUTPUT_CHANNELS = 2\n",
    "HIDDEN_CHANNELS = 64\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.conv1 = GraphConv(INPUT_CHANNELS, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, OUTPUT_CHANNELS)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def read_reactome_graph(e_fn):\n",
    "    e_v1 = []\n",
    "    e_v2 = []\n",
    "\n",
    "    for line in open(e_fn, 'r'):\n",
    "        dt = line.split()\n",
    "        node1 = int(dt[0]) - 1  # subtracting to convert R idx to python idx\n",
    "        node2 = int(dt[1]) - 1  # \" \"\n",
    "        e_v1.append(node1)\n",
    "        e_v2.append(node2)\n",
    "\n",
    "    return e_v1, e_v2\n",
    "\n",
    "\n",
    "def build_reactome_graph_datalist(e_v1, e_v2, n_features_fn, g_targets_fn):\n",
    "    edge_index = torch.tensor([e_v1, e_v2], dtype=torch.long)\n",
    "    feature_v = numpy.loadtxt(n_features_fn)\n",
    "    t_v = numpy.loadtxt(g_targets_fn, dtype=float, delimiter=\",\")\n",
    "\n",
    "    binary_labels = (t_v > 0).astype(int)\n",
    "\n",
    "    d_list = []\n",
    "    for row_idx in range(len(feature_v)):\n",
    "        x = torch.tensor(feature_v[row_idx, :], dtype=torch.float)\n",
    "        x = x.unsqueeze(1)\n",
    "        y = torch.tensor([binary_labels[row_idx]], dtype=torch.long)\n",
    "        d_list.append(Data(x=x, y=y, edge_index=edge_index))\n",
    "\n",
    "    return d_list\n",
    "\n",
    "\n",
    "def explain(m, dt, target):\n",
    "    input_mask = torch.ones(dt.edge_index.shape[1]).requires_grad_(True).to(device)\n",
    "    if m == 'ig':\n",
    "        ig = IntegratedGradients(model_forward)\n",
    "        mask = ig.attribute(input_mask, target=target,\n",
    "                            additional_forward_args=(dt,),\n",
    "                            internal_batch_size=dt.edge_index.shape[1])\n",
    "    else:\n",
    "        raise Exception('Unknown explanation method')\n",
    "\n",
    "    e_mask = np.abs(mask.cpu().detach().numpy())\n",
    "    if e_mask.max() > 0:  # avoid division by zero\n",
    "        e_mask = e_mask / e_mask.max()\n",
    "    return e_mask\n",
    "\n",
    "\n",
    "def aggregate_edge_directions(e_mask, dt):\n",
    "    edge_mask_dict = defaultdict(float)\n",
    "    for val, u, v in list(zip(e_mask, *dt.edge_index)):\n",
    "        u, v = u.item(), v.item()\n",
    "        if u > v:\n",
    "            u, v = v, u\n",
    "        edge_mask_dict[(u, v)] += val\n",
    "    return edge_mask_dict\n",
    "\n",
    "\n",
    "def model_forward(e_mask, dt):\n",
    "    batch = torch.zeros(dt.x.shape[0], dtype=int).to(device)\n",
    "    out = model(dt.x,\n",
    "                dt.edge_index,\n",
    "                batch,\n",
    "                e_mask)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b083688f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/yuankeji/anaconda3/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_v saved as /mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/transformed_targets030.txt\n",
      "target_l saved as /mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/inverted_targets030.txt\n",
      "processing tissue 0 with Integrated Gradients, a.k.a. ig\n",
      "ig 0 edges saved as /mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/ig_0030.txt\n",
      "processing tissue 1 with Integrated Gradients, a.k.a. ig\n",
      "ig 1 edges saved as /mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/ig_1030.txt\n"
     ]
    }
   ],
   "source": [
    "(edge_v1, edge_v2) = read_reactome_graph(edges_fn)\n",
    "\n",
    "data_list = build_reactome_graph_datalist(edge_v1, edge_v2, node_features_fn, graph_targets_fn)\n",
    "data_loader = DataLoader(data_list)\n",
    "\n",
    "# rebuild label encoder to invert numerical transformation\n",
    "target_v = numpy.loadtxt(graph_targets_fn, dtype=str, delimiter=\",\")\n",
    "target_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "\n",
    "target_v = target_encoder.fit_transform(target_v)\n",
    "path = transformed_targets_fn\n",
    "numpy.savetxt(path, target_v, delimiter=\",\", fmt=\"%.0f\")\n",
    "print(F\"target_v saved as {path}\")\n",
    "\n",
    "target_l = target_encoder.inverse_transform(target_v)\n",
    "path = inverted_targets_fn\n",
    "numpy.savetxt(path, target_l, delimiter=\",\", fmt=\"%s\")\n",
    "print(F\"target_l saved as {path}\")\n",
    "\n",
    "model = GNN(hidden_channels=HIDDEN_CHANNELS)\n",
    "device = cpu = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "path = model_fn\n",
    "model.load_state_dict(torch.load(path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "d = data_loader.dataset[0]\n",
    "d.edge_index.shape[1]\n",
    "\n",
    "data = data_loader.dataset[0]\n",
    "\n",
    "for target_tissue in range(2):\n",
    "    title = 'Integrated Gradients'\n",
    "    method = 'ig'\n",
    "    data.to(device)\n",
    "    print(F\"processing tissue {target_tissue} with {title}, a.k.a. {method}\")\n",
    "    edge_mask = explain(method, data, target=target_tissue)\n",
    "    # edge_mask_dict = aggregate_edge_directions(edge_mask, data)\n",
    "    path = F\"/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/tcdd/output/{method}_{target_tissue}030.txt\"\n",
    "    numpy.savetxt(path, edge_mask, delimiter=\",\")\n",
    "    print(F\"{method} {target_tissue} edges saved as {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5754c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
