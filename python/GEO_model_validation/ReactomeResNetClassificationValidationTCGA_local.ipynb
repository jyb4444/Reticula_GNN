{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import sklearn\n",
    "import torch.nn.functional as nn_func\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "random.seed = 88888888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ff2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_validation/input/node_features.txt'\n",
    "graph_targets_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_validation/input/graph_targets.txt'\n",
    "model_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_training/GNN/trained_pytorch_model_fold_full_dataset.pt'\n",
    "output_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_validation/output/resnet_predictions.tsv'\n",
    "sampleID_fn = '/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_validation/input/sample_id.txt'\n",
    "\n",
    "features_exist = op.exists(node_features_fn)\n",
    "targets_exist = op.exists(graph_targets_fn)\n",
    "model_exists = op.exists(model_fn)\n",
    "\n",
    "print(f'features exist: {features_exist},'\n",
    "      f' targets exist: {targets_exist},'\n",
    "      f' model exists: {model_exists}')\n",
    "assert features_exist\n",
    "assert targets_exist\n",
    "assert model_exists\n",
    "\n",
    "# magic numbers\n",
    "INPUT_CHANNELS = 1\n",
    "OUTPUT_CHANNELS = 51\n",
    "NEW_CHANNELS = 13\n",
    "HIDDEN_CHANNELS = 64\n",
    "BATCH_SIZE = 64\n",
    "BENCHMARKING = False\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eed64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_reactome_graph(e_fn):\n",
    "    e_v1 = []\n",
    "    e_v2 = []\n",
    "\n",
    "    for line in open(e_fn, 'r'):\n",
    "        dt = line.split()\n",
    "        node1 = int(dt[0]) - 1  # subtracting to convert R idx to python idx\n",
    "        node2 = int(dt[1]) - 1  # \" \"\n",
    "        e_v1.append(node1)\n",
    "        e_v2.append(node2)\n",
    "\n",
    "    return e_v1, e_v2\n",
    "\n",
    "\n",
    "def build_resnet_datalist(n_features_fn, g_targets_fn, s_fn):\n",
    "    feature_v = numpy.loadtxt(n_features_fn)\n",
    "    target_v = numpy.loadtxt(g_targets_fn, dtype=str, delimiter=\",\")\n",
    "    sampleID_v = numpy.loadtxt(s_fn, dtype=str, delimiter=\",\")\n",
    "\n",
    "    target_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    target_v = target_encoder.fit_transform(target_v)\n",
    "    label_mapping = dict(zip(target_encoder.transform(target_encoder.classes_), target_encoder.classes_))\n",
    "    print(label_mapping)\n",
    "\n",
    "    d_list = []\n",
    "    for row_idx in range(len(feature_v)):\n",
    "        x = torch.tensor(feature_v[row_idx, :], dtype=torch.float)\n",
    "        x = x.reshape(2, 8, 491)\n",
    "        y = torch.tensor([target_v[row_idx]])\n",
    "        sample_id = sampleID_v[row_idx]\n",
    "        tissue = label_mapping[target_v[row_idx]]\n",
    "        \n",
    "        d_list.append({'x': x, 'y': y, 'sid': sample_id, 'tissue': tissue})\n",
    "\n",
    "    return d_list\n",
    "\n",
    "\n",
    "def build_reactome_graph_loader(d_list, batch_size):\n",
    "    loader = DataLoader(d_list, batch_size=batch_size, shuffle=False)  # True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def train(loader, dv):\n",
    "    model.train()\n",
    "\n",
    "    correct = 0\n",
    "    for batch in loader:  # Iterate in batches over the training dataset.\n",
    "        x = batch['x'].to(dv)\n",
    "        y = batch['y'].to(dv)\n",
    "        out = model(x)  # Perform a single forward pass.\n",
    "        y = torch.squeeze(y)\n",
    "        loss = criterion(out, y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "def test(loader, dv):\n",
    "    model.eval()\n",
    "\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    sample_ids = []\n",
    "    tissues = []\n",
    "    confidences = []\n",
    "    for batch in loader:  # Iterate in batches over the test dataset.\n",
    "        x = batch['x'].to(dv)\n",
    "        y = batch['y'].to(dv)\n",
    "        targets += torch.Tensor.tolist(torch.squeeze(y))\n",
    "        sample_ids += batch['sid']\n",
    "        tissues += batch['tissue']\n",
    "        out = model(x)  # Perform a single forward pass.\n",
    "        prob = torch.softmax(out, dim=1)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        predictions += torch.Tensor.tolist(pred)\n",
    "        confidences += torch.Tensor.tolist(prob)\n",
    "        \n",
    "    # Save targets, predictions, and confidences to a file\n",
    "    num_classes = len(confidences[0])\n",
    "    # Flatten confidences and create data for saving\n",
    "    data_to_save = []\n",
    "    for i in range(len(targets)):\n",
    "        row = [sample_ids[i], tissues[i], targets[i], predictions[i]] + confidences[i]\n",
    "        data_to_save.append(row)\n",
    "    data_to_save = numpy.array(data_to_save)\n",
    "    print(data_to_save)\n",
    "    \n",
    "    fmt = ['%s', '%s', '%s', '%s'] + ['%s' for _ in range(num_classes)]\n",
    "    \n",
    "    headers = ['sample_ids', 'tissues', 'target', 'prediction'] + [f'confidence_class_{i}' for i in range(num_classes)]\n",
    "    numpy.savetxt(output_fn, data_to_save, fmt='\\t'.join(fmt), delimiter='\\t', header='\\t'.join(headers), comments='')\n",
    "    ari = adjusted_rand_score(targets, predictions)\n",
    "    print(f'ari: {ari}')\n",
    "    return ari\n",
    "\n",
    "def change_key(self, old, new):\n",
    "    for _ in range(len(self)):\n",
    "        k, v = self.popitem(False)\n",
    "        self[new if old == k else k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1f83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(num_classes=26)\n",
    "conv1 = model.conv1\n",
    "model.conv1 = nn.Conv2d(2,\n",
    "                        conv1.out_channels,\n",
    "                        conv1.kernel_size,\n",
    "                        conv1.stride,\n",
    "                        conv1.padding,\n",
    "                        conv1.dilation,\n",
    "                        conv1.groups,\n",
    "                        conv1.bias)\n",
    "device = cpu = torch.device('cpu')\n",
    "\n",
    "sd = torch.load(model_fn, map_location=device)\n",
    "\n",
    "model.load_state_dict(sd, strict=False)\n",
    "\n",
    "model.fc = Linear(in_features=model.fc.in_features,\n",
    "                  out_features=NEW_CHANNELS,\n",
    "                  bias=True)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "data_list = build_resnet_datalist(node_features_fn, graph_targets_fn, sampleID_fn)\n",
    "print(len(data_list))\n",
    "# retrain model for fine tuning transfer learning\n",
    "train_data_list = data_list[0::2]\n",
    "print(len(train_data_list))\n",
    "print(f'Number of training graphs: {len(train_data_list)}')\n",
    "train_data_loader = build_reactome_graph_loader(train_data_list, BATCH_SIZE)\n",
    "for epoch in range(EPOCHS):\n",
    "    train(train_data_loader, device)\n",
    "    train_acc = train(train_data_loader, device)\n",
    "    print(f'Epoch: {epoch}, Train Acc: {train_acc}')\n",
    "    if train_acc == 1.0:\n",
    "        break\n",
    "\n",
    "test_data_list = data_list[1::2]\n",
    "print(len(test_data_list))\n",
    "print(f'Number of test graphs: {len(test_data_list)}')\n",
    "\n",
    "test_data_loader = build_reactome_graph_loader(test_data_list, BATCH_SIZE)\n",
    "test_ari = test(test_data_loader, device)\n",
    "print(f'test_ari: {test_ari}')\n",
    "\n",
    "model_save_name = f'tuned_pytorch_GEO_model_validation_resnet_model.pt'\n",
    "path = f'/mnt/home/yuankeji/RanceLab/reticula_new/reticula/data/GEO_model_validation/GNN/{model_save_name}'\n",
    "torch.save(model.state_dict(), path)\n",
    "print(f'model saved as {path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
